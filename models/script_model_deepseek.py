import os
import requests
from huggingface_hub import HfApi

# Configura√ß√µes do modelo
REPO_ID = "deepseek-ai/DeepSeek-R1"  # Reposit√≥rio do modelo
MODEL_PATH = "models/deepseek_r1"    # Pasta onde o modelo ser√° salvo
HF_TOKEN = "SEU_TOKEN_AQUI"          # Substitua pelo seu token de acesso

def get_model_files():
    """
    Obt√©m a lista de arquivos do reposit√≥rio do modelo
    """
    api = HfApi(token=HF_TOKEN)
    
    try:
        # Listar todos os arquivos do reposit√≥rio
        files = api.list_repo_files(repo_id=REPO_ID, repo_type="model")
        return files
    except Exception as e:
        raise RuntimeError(f"Erro ao acessar o reposit√≥rio: {str(e)}")

def download_model():
    """
    Baixa o modelo DeepSeek-R1
    """
    # Criar pasta models/ se n√£o existir
    if not os.path.exists("models"):
        os.makedirs("models")
        print("üìÅ Pasta 'models/' criada.")

    # Verificar se o modelo j√° existe
    if os.path.exists(MODEL_PATH):
        print("‚úÖ Modelo j√° baixado.")
        return

    try:
        # Obter a lista de arquivos do reposit√≥rio
        files = get_model_files()
        print(f"üîç Arquivos encontrados no reposit√≥rio: {files}")

        # Baixar cada arquivo do reposit√≥rio
        for file in files:
            file_url = f"https://huggingface.co/{REPO_ID}/resolve/main/{file}"
            file_path = os.path.join(MODEL_PATH, file)
            
            # Criar subpastas, se necess√°rio
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            print(f"‚¨áÔ∏è Baixando {file}...")
            
            # Fazer o download do arquivo com autentica√ß√£o
            headers = {"Authorization": f"Bearer {HF_TOKEN}"}
            response = requests.get(file_url, headers=headers, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get("content-length", 0))
            downloaded_size = 0

            with open(file_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        if total_size > 0:
                            progress = downloaded_size / total_size * 100
                            print(f"Progresso: {progress:.2f}% ({downloaded_size}/{total_size} bytes)", end="\r")
            
            print(f"\n‚úÖ {file} baixado com sucesso!")

        print("\n‚úÖ Todos os arquivos do modelo foram baixados!")

    except Exception as e:
        print(f"‚ùå Erro durante o download: {str(e)}")
        if os.path.exists(MODEL_PATH):
            os.remove(MODEL_PATH)

if __name__ == "__main__":
    download_model()